{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 1s 869ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000012E7CB81160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "Predicted values saved to predict.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Flatten, Conv1D, MaxPooling1D, GRU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load data from CSV file\n",
    "data_df = pd.read_csv('dataavg.csv')\n",
    "\n",
    "# Function to create time series data\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# Train model\n",
    "def train_model(model, X_train, y_train):\n",
    "    model.compile(optimizer=tf.compat.v1.train.AdamOptimizer(), loss='mean_squared_error')\n",
    "    history = model.fit(X_train, y_train, epochs=70, batch_size=16, validation_split=0.1, verbose=0)\n",
    "    return model, history\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data_df['Avg_Power'].values.reshape(-1, 1))\n",
    "\n",
    "# Create time series data\n",
    "X_train, y_train = create_dataset(scaled_data, scaled_data, time_steps=10)\n",
    "\n",
    "# LSTM model\n",
    "model_lstm = Sequential([\n",
    "    LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model_lstm, history_lstm = train_model(model_lstm, X_train, y_train)\n",
    "\n",
    "# Bi-LSTM model\n",
    "model_bilstm = Sequential([\n",
    "    Bidirectional(LSTM(units=64), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model_bilstm, history_bilstm = train_model(model_bilstm, X_train, y_train)\n",
    "\n",
    "# FNN model\n",
    "model_fnn = Sequential([\n",
    "    Flatten(input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model_fnn, history_fnn = train_model(model_fnn, X_train, y_train)\n",
    "\n",
    "# CNN model\n",
    "model_cnn = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model_cnn, history_cnn = train_model(model_cnn, X_train, y_train)\n",
    "\n",
    "# GRU model\n",
    "model_gru = Sequential([\n",
    "    GRU(units=64, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(units=1)\n",
    "])\n",
    "\n",
    "model_gru, history_gru = train_model(model_gru, X_train, y_train)\n",
    "\n",
    "# Select the last 10 data points from the dataset\n",
    "last_data_points = scaled_data[-10:]\n",
    "\n",
    "# Reshape the data to match the input shape of the models\n",
    "last_data_points = last_data_points.reshape((1, 10, 1))\n",
    "\n",
    "# Predict the power output for the next hour using each model\n",
    "next_hour_pred_lstm = model_lstm.predict(last_data_points)[0][0]\n",
    "next_hour_pred_bilstm = model_bilstm.predict(last_data_points)[0][0]\n",
    "next_hour_pred_fnn = model_fnn.predict(last_data_points)[0][0]\n",
    "next_hour_pred_cnn = model_cnn.predict(last_data_points)[0][0]\n",
    "next_hour_pred_gru = model_gru.predict(last_data_points)[0][0]\n",
    "\n",
    "# Invert the scaling to get the actual power output values\n",
    "next_hour_pred_lstm = scaler.inverse_transform(np.array([[next_hour_pred_lstm]]))[0][0]\n",
    "next_hour_pred_bilstm = scaler.inverse_transform(np.array([[next_hour_pred_bilstm]]))[0][0]\n",
    "next_hour_pred_fnn = scaler.inverse_transform(np.array([[next_hour_pred_fnn]]))[0][0]\n",
    "next_hour_pred_cnn = scaler.inverse_transform(np.array([[next_hour_pred_cnn]]))[0][0]\n",
    "next_hour_pred_gru = scaler.inverse_transform(np.array([[next_hour_pred_gru]]))[0][0]\n",
    "\n",
    "# Save predicted values to a CSV file\n",
    "with open('predict.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['LSTM', 'Bi-LSTM', 'FNN', 'CNN', 'GRU'])\n",
    "    writer.writerow([next_hour_pred_lstm, next_hour_pred_bilstm, next_hour_pred_fnn, next_hour_pred_cnn, next_hour_pred_gru])\n",
    "\n",
    "# Print the predicted values\n",
    "print(\"Predicted values saved to predict.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
